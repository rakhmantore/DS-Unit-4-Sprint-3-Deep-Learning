{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S3-MNA-DS11",
      "language": "python",
      "name": "u4-s3-mna-ds11"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.23.3"
    },
    "colab": {
      "name": "LS_DS_431_RNN_and_LSTM_Assignment.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZpoJJvf3bJC"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-06-15T18:18:20.442Z",
          "iopub.execute_input": "2020-06-15T18:18:20.453Z",
          "iopub.status.idle": "2020-06-15T18:18:20.513Z",
          "shell.execute_reply": "2020-06-15T18:18:20.523Z"
        },
        "id": "UFxJ5NSP3bJD"
      },
      "source": [
        "import requests\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-06-15T18:25:49.778Z",
          "iopub.execute_input": "2020-06-15T18:25:49.781Z",
          "iopub.status.idle": "2020-06-15T18:25:51.467Z",
          "shell.execute_reply": "2020-06-15T18:25:51.469Z"
        },
        "id": "BFpIy73g3bJE"
      },
      "source": [
        "url = \"https://www.gutenberg.org/files/100/100-0.txt\"\n",
        "\n",
        "r = requests.get(url)\n",
        "r.encoding = r.apparent_encoding\n",
        "data = r.text\n",
        "data = data.split('\\r\\n')\n",
        "toc = [l.strip() for l in data[44:130:2]]\n",
        "# Skip the Table of Contents\n",
        "data = data[135:]\n",
        "\n",
        "# Fixing Titles\n",
        "toc[9] = 'THE LIFE OF KING HENRY V'\n",
        "toc[18] = 'MACBETH'\n",
        "toc[24] = 'OTHELLO, THE MOOR OF VENICE'\n",
        "toc[34] = 'TWELFTH NIGHT: OR, WHAT YOU WILL'\n",
        "\n",
        "locations = {id_:{'title':title, 'start':-99} for id_,title in enumerate(toc)}\n",
        "\n",
        "# Start \n",
        "for e,i in enumerate(data):\n",
        "    for t,title in enumerate(toc):\n",
        "        if title in i:\n",
        "            locations[t].update({'start':e})\n",
        "            \n",
        "\n",
        "df_toc = pd.DataFrame.from_dict(locations, orient='index')\n",
        "df_toc['end'] = df_toc['start'].shift(-1).apply(lambda x: x-1)\n",
        "df_toc.loc[42, 'end'] = len(data)\n",
        "df_toc['end'] = df_toc['end'].astype('int')\n",
        "\n",
        "df_toc['text'] = df_toc.apply(lambda x: '\\r\\n'.join(data[ x['start'] : int(x['end']) ]), axis=1)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtuCny1TIAlZ",
        "outputId": "d1100a09-3455-42eb-b0d9-5f7ecbb6242b"
      },
      "source": [
        "toc"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['THE TRAGEDY OF ANTONY AND CLEOPATRA',\n",
              " 'AS YOU LIKE IT',\n",
              " 'THE COMEDY OF ERRORS',\n",
              " 'THE TRAGEDY OF CORIOLANUS',\n",
              " 'CYMBELINE',\n",
              " 'THE TRAGEDY OF HAMLET, PRINCE OF DENMARK',\n",
              " 'THE FIRST PART OF KING HENRY THE FOURTH',\n",
              " 'THE SECOND PART OF KING HENRY THE FOURTH',\n",
              " 'THE LIFE OF KING HENRY THE FIFTH',\n",
              " 'THE LIFE OF KING HENRY V',\n",
              " 'THE SECOND PART OF KING HENRY THE SIXTH',\n",
              " 'THE THIRD PART OF KING HENRY THE SIXTH',\n",
              " 'KING HENRY THE EIGHTH',\n",
              " 'KING JOHN',\n",
              " 'THE TRAGEDY OF JULIUS CAESAR',\n",
              " 'THE TRAGEDY OF KING LEAR',\n",
              " 'LOVE’S LABOUR’S LOST',\n",
              " 'THE TRAGEDY OF MACBETH',\n",
              " 'MACBETH',\n",
              " 'THE MERCHANT OF VENICE',\n",
              " 'THE MERRY WIVES OF WINDSOR',\n",
              " 'A MIDSUMMER NIGHT’S DREAM',\n",
              " 'MUCH ADO ABOUT NOTHING',\n",
              " 'THE TRAGEDY OF OTHELLO, MOOR OF VENICE',\n",
              " 'OTHELLO, THE MOOR OF VENICE',\n",
              " 'KING RICHARD THE SECOND',\n",
              " 'KING RICHARD THE THIRD',\n",
              " 'THE TRAGEDY OF ROMEO AND JULIET',\n",
              " 'THE TAMING OF THE SHREW',\n",
              " 'THE TEMPEST',\n",
              " 'THE LIFE OF TIMON OF ATHENS',\n",
              " 'THE TRAGEDY OF TITUS ANDRONICUS',\n",
              " 'THE HISTORY OF TROILUS AND CRESSIDA',\n",
              " 'TWELFTH NIGHT; OR, WHAT YOU WILL',\n",
              " 'TWELFTH NIGHT: OR, WHAT YOU WILL',\n",
              " 'THE TWO NOBLE KINSMEN',\n",
              " 'THE WINTER’S TALE',\n",
              " 'A LOVER’S COMPLAINT',\n",
              " 'THE PASSIONATE PILGRIM',\n",
              " 'THE PHOENIX AND THE TURTLE',\n",
              " 'THE RAPE OF LUCRECE',\n",
              " 'VENUS AND ADONIS',\n",
              " '']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-06-15T18:26:12.630Z",
          "iopub.execute_input": "2020-06-15T18:26:12.637Z",
          "iopub.status.idle": "2020-06-15T18:26:12.643Z",
          "shell.execute_reply": "2020-06-15T18:26:12.647Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-gN4CP5M3bJE",
        "outputId": "e726cab7-c1c2-4c6c-c9db-af0d9c33a9c6"
      },
      "source": [
        "#Shakespeare Data Parsed by Play\n",
        "df_toc.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>THE TRAGEDY OF ANTONY AND CLEOPATRA</td>\n",
              "      <td>-99</td>\n",
              "      <td>14379</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AS YOU LIKE IT</td>\n",
              "      <td>14380</td>\n",
              "      <td>17171</td>\n",
              "      <td>AS YOU LIKE IT\\r\\n\\r\\n\\r\\nDRAMATIS PERSONAE.\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>THE COMEDY OF ERRORS</td>\n",
              "      <td>17172</td>\n",
              "      <td>20372</td>\n",
              "      <td>THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS</td>\n",
              "      <td>20373</td>\n",
              "      <td>30346</td>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CYMBELINE</td>\n",
              "      <td>30347</td>\n",
              "      <td>30364</td>\n",
              "      <td>CYMBELINE.\\r\\nLaud we the gods;\\r\\nAnd let our...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 title  ...                                               text\n",
              "0  THE TRAGEDY OF ANTONY AND CLEOPATRA  ...                                                   \n",
              "1                       AS YOU LIKE IT  ...  AS YOU LIKE IT\\r\\n\\r\\n\\r\\nDRAMATIS PERSONAE.\\r...\n",
              "2                 THE COMEDY OF ERRORS  ...  THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...\n",
              "3            THE TRAGEDY OF CORIOLANUS  ...  THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...\n",
              "4                            CYMBELINE  ...  CYMBELINE.\\r\\nLaud we the gods;\\r\\nAnd let our...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AC3BpIwwIXEP",
        "outputId": "e8d96264-5258-4852-911b-c351a3b490ec"
      },
      "source": [
        "df_toc.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(43, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sw7QkRsAK880"
      },
      "source": [
        "pre_text = df_toc[\"text\"].values.tolist()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nhq_GlmN4cNq"
      },
      "source": [
        "pre_text = \" \".join(data)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pLNvVd8G1-z"
      },
      "source": [
        "chars = list(set(pre_text))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5YJ2hVwG6DU",
        "outputId": "8adf04d7-a12d-4cdc-c6c4-f94efe7edc3c"
      },
      "source": [
        "len(chars)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "104"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBgnfCcmHUDE"
      },
      "source": [
        "# Lookup Tables\n",
        "char_int = {c:i for i, c in enumerate(chars)} \n",
        "int_char = {i:c for i, c in enumerate(chars)} "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIVs7EzVHW2D",
        "outputId": "369e9d90-d7a1-4029-efd9-26d2c40f98eb"
      },
      "source": [
        "# Create the sequence data\n",
        "maxlen = 40\n",
        "step = 5\n",
        "\n",
        "encoded = [char_int[c] for c in pre_text]\n",
        "\n",
        "sequences = [] # Each element is 40 chars long\n",
        "next_char = [] # One element for each sequence\n",
        "\n",
        "for i in range(0, len(encoded) - maxlen, step):\n",
        "    \n",
        "    sequences.append(encoded[i : i + maxlen])\n",
        "    next_char.append(encoded[i + maxlen])\n",
        "    \n",
        "print('sequences: ', len(sequences))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sequences:  1111146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKrIukX1HdLS",
        "outputId": "64136ee2-0545-449f-8619-9c717df66164"
      },
      "source": [
        "sequences[0]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 78,\n",
              " 1,\n",
              " 1,\n",
              " 18,\n",
              " 19,\n",
              " 24,\n",
              " 11,\n",
              " 1,\n",
              " 76,\n",
              " 56,\n",
              " 101,\n",
              " 19,\n",
              " 44,\n",
              " 66,\n",
              " 28,\n",
              " 1,\n",
              " 3,\n",
              " 19,\n",
              " 44,\n",
              " 56]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8sT4VlGHoof",
        "outputId": "1870d54a-41fc-4316-a317-58edde8b0cf9"
      },
      "source": [
        "[int_char[i] for i in sequences[0]]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " '1',\n",
              " ' ',\n",
              " ' ',\n",
              " 'F',\n",
              " 'r',\n",
              " 'o',\n",
              " 'm',\n",
              " ' ',\n",
              " 'f',\n",
              " 'a',\n",
              " 'i',\n",
              " 'r',\n",
              " 'e',\n",
              " 's',\n",
              " 't',\n",
              " ' ',\n",
              " 'c',\n",
              " 'r',\n",
              " 'e',\n",
              " 'a']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq2RDJjbnO0A"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LbjbxNgH1OA"
      },
      "source": [
        "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sequences),len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sequence in enumerate(sequences):\n",
        "    for t, char in enumerate(sequence):\n",
        "        x[i,t,char] = 1\n",
        "    y[i, next_char[i]] = 1"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHbkltbFqJL9",
        "outputId": "10fc0444-9b16-41f9-fdef-80e69c922dca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1111146, 40, 104)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ttC5xrIqL4K",
        "outputId": "e330973a-dae9-442f-d9a8-0cc4112afce9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1111146, 104)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iQk69L3qInD"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Dropout, SimpleRNN, LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysbbrxr6qpTr"
      },
      "source": [
        "import random\n",
        "import sys\n",
        "import os\n",
        "def sample(preds):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / 1\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbOnn05ArOmW"
      },
      "source": [
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    \n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    \n",
        "    start_index = random.randint(0, len(pre_text) - maxlen - 1) \n",
        "    generated = ''\n",
        "    \n",
        "    sentence = pre_text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    \n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "    \n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_int[char]] = 1\n",
        "            \n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = int_char[next_index]\n",
        "        \n",
        "        sentence = sentence[1:] + next_char\n",
        "        \n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "\n",
        "    print()\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg8xZduiralv",
        "outputId": "973fed6d-e05b-4169-e752-b96dcc7e2e50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(x, y,\n",
        "          batch_size=32,\n",
        "          epochs=5,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "34723/34724 [============================>.] - ETA: 0s - loss: 1.6333\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \"t especially where he speaks of Priam’s \"\n",
            "t especially where he speaks of Priam’s connoble     Singat, here apptaluce are weels a deallys shou bown more than old     be a wretche     Should want the Proudiness like eyes I'll before glad to never sure not, A0t; dost flowred this plainto, and Myhe's staeb!  IACHIMON. Marker dature Can’ay loun’s freid, of ray.  KENT. O Well, hearing.  TINO. The fortune abould firescalred.   PRINI; As muce all of thy did a liets, or minded a course\n",
            "34724/34724 [==============================] - 169s 5ms/step - loss: 1.6333\n",
            "Epoch 2/5\n",
            "34716/34724 [============================>.] - ETA: 0s - loss: 1.5807\n",
            "----- Generating text after Epoch: 1\n",
            "----- Generating with seed: \"NUS. I do beseech you     Let me o'erlea\"\n",
            "NUS. I do beseech you     Let me o'erlearor. Let this intried yenderous, And jowncty, the this women     And hanst Prenchsore?  SIR KICTLES. How rast, dotroul do, mirry at father’d     To fear to burthing ronon?  PELENBUSH. You kis to gee, reag, and thee.  JALBIA. I will not Say you so love on your bust great and hear Shrid I speep mignance,     to mose, terd adgender it is clavour’d authour conwer; of affing their loud, with up:     Ta\n",
            "34724/34724 [==============================] - 169s 5ms/step - loss: 1.5807\n",
            "Epoch 3/5\n",
            "34720/34724 [============================>.] - ETA: 0s - loss: 1.5436\n",
            "----- Generating text after Epoch: 2\n",
            "----- Generating with seed: \"nds; nay, dry your eyes:     Tears show \"\n",
            "nds; nay, dry your eyes:     Tears show this dook the ward madlerous; when there was my counten noble sor     Jove, kill me after mistred     A well her, good lashy;     Fay by mine eyest at whilus may shall let,     peam is do come             '                    144   And both Jusembled to were brother     a movance of han in?  FIRST HORATIO. Who his landder. Come dauchs!         KING PENTAR TROSES OF WOLAMON CoSTessine, and to a par\n",
            "34724/34724 [==============================] - 170s 5ms/step - loss: 1.5436\n",
            "Epoch 4/5\n",
            "34713/34724 [============================>.] - ETA: 0s - loss: 1.5212\n",
            "----- Generating text after Epoch: 3\n",
            "----- Generating with seed: \"th others.  ANTONY. We have beat him to \"\n",
            "th others.  ANTONY. We have beat him to fear;     And let you jase.  BOLINGUS. You’ll you.  PESS. Though towardsty me so black in them you.  [Exeunt._]  I have are King to tell the life daughter to-comfenger.  CLEONTES. I do thy charing inchase Is desirul, And one soul glow no glid'd, To man's King, Marchuron mire of but what maithes.  HELIDAMOLN. Alexame to Greeke me in to Andone deserfy.   MARCIUS. Thou are you laugh emplother, Locks \n",
            "34724/34724 [==============================] - 168s 5ms/step - loss: 1.5212\n",
            "Epoch 5/5\n",
            "34724/34724 [==============================] - ETA: 0s - loss: 1.5026\n",
            "----- Generating text after Epoch: 4\n",
            "----- Generating with seed: \" thou coward Troilus!   [_Exit_.]  DIOME\"\n",
            " thou coward Troilus!   [_Exit_.]  DIOMERES. Here ever it hand of. ne’en my proofs in her way, Mine a man! Yet son, that, and the owh greveral yours which so!     Yet he a live, even you which their blood for his honour mids' Surpeds, of this noble.  CELARIUS. Heart._  IACHIMBER. You have did be worthy suity branca.  MESSENGER. How myself._]  SECATES. Stall’d her law for so our compair flowt,     Not salain rele Time withom strike in to\n",
            "34724/34724 [==============================] - 168s 5ms/step - loss: 1.5026\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f39dc7787f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE4a4O7Bp5x1"
      },
      "source": [
        "# Resources and Stretch Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "## Stretch goals:\n",
        "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
        "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
        "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
        "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
        "- Run on bigger, better data\n",
        "\n",
        "## Resources:\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
        "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
        "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
        "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
        "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
      ]
    }
  ]
}